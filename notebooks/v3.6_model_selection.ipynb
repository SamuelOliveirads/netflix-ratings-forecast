{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import yeojohnson\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/24/23 12:54:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'train_feature_selection'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/24/23 12:54:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'train_feature_selection'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m        \u001b]8;id=317900;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=561353;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'validation_feature_selection'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>   <a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'validation_feature_selection'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m   \u001b]8;id=234791;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=426757;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'yeojohnson_transformation'</span> <span style=\"font-weight: bold\">(</span>PickleDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>   <a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'yeojohnson_transformation'\u001b[0m \u001b[1m(\u001b[0mPickleDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m   \u001b]8;id=703854;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104575;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'exploratory_data_analysis'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'exploratory_data_analysis'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m      \u001b]8;id=560502;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=760149;file://f:\\SamuelOliveiraAlvesd\\Anaconda3\\envs\\netflix_classifier\\Lib\\site-packages\\kedro\\io\\data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_feature_selection = catalog.load(\"train_feature_selection\")\n",
    "validation_feature_selection = catalog.load(\"validation_feature_selection\")\n",
    "yeojohnson_transformation = catalog.load(\"yeojohnson_transformation\")\n",
    "exploratory_data_analysis = catalog.load(\"exploratory_data_analysis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the next cycle we can modularize the cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notebook_settings():\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', 30)\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    return None\n",
    "\n",
    "\n",
    "def ml_error(model_name, y, yhat):\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame({'Model Name': model_name,\n",
    "                         'MAE' : mae,\n",
    "                         'RMSE': rmse}, index=[0])\n",
    "\n",
    "\n",
    "def yeojohnson_inverse(y):\n",
    "    lambda_val = yeojohnson_transformation.value\n",
    "    \n",
    "    y_positive_mask = y >= 0\n",
    "    y_negative_mask = ~y_positive_mask\n",
    "\n",
    "    result = np.empty_like(y)\n",
    "\n",
    "    if lambda_val == 0:\n",
    "        result[y_positive_mask] = np.exp(y[y_positive_mask]) - 1\n",
    "        result[y_negative_mask] = -np.exp(-y[y_negative_mask]) - 1\n",
    "    elif lambda_val != 0:\n",
    "        result[y_positive_mask] = (lambda_val * y[y_positive_mask] + 1) ** (1 / lambda_val) - 1\n",
    "        result[y_negative_mask] = -((-lambda_val * y[y_negative_mask] + 1) ** (1 / -lambda_val) - 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def cross_validation(df, model, model_name, n_splits=5):\n",
    "    # Create a KFold object\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    # Step 1: Split data\n",
    "    X = df.drop('rating', axis=1)\n",
    "    y = df['rating'].copy()\n",
    "\n",
    "    mae_list_train = []\n",
    "    rmse_list_train = []\n",
    "    mae_list_val = []\n",
    "    rmse_list_val = []\n",
    "\n",
    "    ss = preprocessing.StandardScaler()\n",
    "    mms = preprocessing.MinMaxScaler()\n",
    "    rs = preprocessing.RobustScaler()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # Iterate over each train-test split\n",
    "    for train_indices, val_indices in kf.split(X, y):\n",
    "        train_data = df.iloc[train_indices]\n",
    "        validation_data = df.iloc[val_indices]\n",
    "\n",
    "        # Step 2: data preparation\n",
    "        cols_to_standard = ['minutes']\n",
    "        cols_to_min_max = ['number_of_listed_ins', 'films_per_country']\n",
    "        cols_to_robust = ['release_year', 'years_since_release', 'description_length',\n",
    "                        'number_of_directors', 'number_of_casts', 'number_of_countrys',\n",
    "                        'films_by_director', 'films_by_cast_member', 'films_per_genre']\n",
    "\n",
    "        for col in cols_to_standard:\n",
    "            train_data[col] = ss.fit_transform(train_data[[col]].values)\n",
    "            validation_data[col] = ss.transform(\n",
    "                validation_data[[col]].values\n",
    "            )\n",
    "\n",
    "        for col in cols_to_min_max:\n",
    "            train_data[col] = mms.fit_transform(train_data[[col]].values)\n",
    "            validation_data[col] = mms.transform(\n",
    "                validation_data[[col]].values\n",
    "            )\n",
    "\n",
    "        for col in cols_to_robust:\n",
    "            train_data[col] = rs.fit_transform(train_data[[col]].values)\n",
    "            validation_data[col] = rs.transform(\n",
    "                validation_data[[col]].values\n",
    "            )\n",
    "\n",
    "        # Label - Doesn't respect an order, works well with a lot of single values\n",
    "        cols_to_label = ['title', 'cast', 'description', 'movie_stage']\n",
    "\n",
    "        for col in cols_to_label:\n",
    "            train_data[col] = le.fit_transform(train_data[col])\n",
    "            # Check if there is something not mapped in validation data\n",
    "            validation_data[col] = validation_data[col].map(\n",
    "                lambda s: \"unknown\" if s not in le.classes_ else s\n",
    "            )\n",
    "            # Add the new class 'unknown' if it is not present\n",
    "            if \"unknown\" not in list(le.classes_):\n",
    "                le.classes_ = np.append(le.classes_, \"unknown\")\n",
    "            else:\n",
    "                # The class 'unknown' is already present, ensure that it occurs only once\n",
    "                le.classes_ = np.unique(le.classes_)\n",
    "            validation_data[col] = le.transform(validation_data[col])\n",
    "\n",
    "        # Ordinal - preserve the order\n",
    "        duration_dict = {'short' : 1, 'medium' : 2, 'long' : 3}\n",
    "        train_data['duration_bins'] = train_data['duration_bins'].map(duration_dict)\n",
    "        validation_data['duration_bins'] = validation_data['duration_bins'].map(duration_dict)\n",
    "\n",
    "        # Frequency encoding - useful for high cardinality columns\n",
    "        cols_to_frequency = ['director', 'country', 'listed_in']\n",
    "\n",
    "        for col in cols_to_frequency:\n",
    "            fe_encoder = train_data.groupby(col).size() / len(train_data)\n",
    "            train_data.loc[:, col] = train_data[col].map(fe_encoder)\n",
    "            train_data[col] = train_data[col].astype('float64')\n",
    "            \n",
    "            # For validation data, replace values with their respective frequencies.\n",
    "            # If the value is not found in the mapping (from train_data), replace with the average frequency from train_data.\n",
    "            validation_data.loc[:, col] = validation_data[col].map(fe_encoder).fillna(fe_encoder.mean())\n",
    "            validation_data[col] = validation_data[col].astype('float64')\n",
    "\n",
    "        train_data['rating'], _ = yeojohnson(train_data['rating'])\n",
    "\n",
    "        # Step 3: Feature selection\n",
    "        cols_feature_importance = ['minutes', 'release_year', 'listed_in', 'description_length', \n",
    "                                'films_by_cast_member', 'films_per_genre', 'description', \n",
    "                                'number_of_casts', 'cast']\n",
    "\n",
    "        train_data[list(cols_feature_importance) + ['show_id', 'date_added', 'rating']]\n",
    "        validation_data[list(cols_feature_importance) + ['show_id', 'date_added', 'rating']]\n",
    "\n",
    "        # Step 4: Model\n",
    "        cols_drop = ['show_id', 'date_added', 'rating']\n",
    "\n",
    "        # training dataset\n",
    "        y_train = train_data['rating']\n",
    "        x_train = train_data.drop(cols_drop, axis=1)\n",
    "\n",
    "        # validation dataset\n",
    "        y_val = validation_data['rating']\n",
    "        x_val = validation_data.drop(cols_drop, axis=1)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_hat_train = model.predict(x_train)\n",
    "        y_hat_val = model.predict(x_val)\n",
    "\n",
    "        # performance\n",
    "        lr_result_train = ml_error(model_name + ' Train', yeojohnson_inverse(y_train), \n",
    "                                yeojohnson_inverse(y_hat_train))\n",
    "        lr_result_val = ml_error(model_name + ' Val', y_val, \n",
    "                                yeojohnson_inverse(y_hat_val))\n",
    "        \n",
    "        # Appending results\n",
    "        mae_list_train.append(lr_result_train['MAE'])\n",
    "        rmse_list_train.append(lr_result_train['RMSE'])\n",
    "        mae_list_val.append(lr_result_val['MAE'])\n",
    "        rmse_list_val.append(lr_result_val['RMSE'])\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            'Model name': model_name + ' Train',\n",
    "            'MAE CV': np.round(np.mean(mae_list_train), 2).astype(str) + ' +/- ' + np.round(np.std(mae_list_train), 2).astype(str),\n",
    "            'RMSE CV': np.round(np.mean(rmse_list_train), 2).astype(str) + ' +/- ' + np.round(np.std(rmse_list_train), 2).astype(str)\n",
    "        },\n",
    "        {\n",
    "            'Model name': model_name + ' Val',\n",
    "            'MAE CV': np.round(np.mean(mae_list_val), 2).astype(str) + ' +/- ' + np.round(np.std(mae_list_val), 2).astype(str),\n",
    "            'RMSE CV': np.round(np.mean(rmse_list_val), 2).astype(str) + ' +/- ' + np.round(np.std(rmse_list_val), 2).astype(str)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Return the final dataframe\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "notebook_settings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics:\n",
    "- For general contexts the MAPE would be an excellent metric due to its percentage calculation, however the characteristics of the data do not allow a good interpretation (typically because it contains 0 data), in this situation we will use the MAE to report to the business and the RMSE to monitor the model in order to identify the impact of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['show_id', 'date_added', 'rating']\n",
    "\n",
    "# training dataset\n",
    "y_train = train_feature_selection['rating']\n",
    "x_train = train_feature_selection.drop(cols_drop, axis=1)\n",
    "\n",
    "# validation dataset\n",
    "y_val = validation_feature_selection['rating']\n",
    "x_val = validation_feature_selection.drop(cols_drop, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Average model - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = validation_feature_selection.copy()\n",
    "aux1['rating'] = y_val.copy()\n",
    "\n",
    "# prediction - We'll do a weighted average by media category\n",
    "aux2 = aux1[['listed_in', 'rating']].groupby('listed_in').mean().reset_index().rename(columns={'rating': 'predictions'})\n",
    "aux1 = pd.merge(aux1, aux2, how='left', on='listed_in')\n",
    "yhat_baseline = aux1['predictions']\n",
    "\n",
    "# performance\n",
    "baseline_result = ml_error('Average Model', y_val, yhat_baseline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_lr_train = lr.predict(x_train)\n",
    "yhat_lr = lr.predict(x_val)\n",
    "\n",
    "# performance\n",
    "lr_result_train = ml_error('Linear Regression Train', yeojohnson_inverse(y_train), \n",
    "                           yeojohnson_inverse(yhat_lr_train))\n",
    "lr_result_val = ml_error('Linear Regression Val', y_val, \n",
    "                         yeojohnson_inverse(yhat_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Linear Regression Model  - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr_result_cv = cross_validation(exploratory_data_analysis, lr, 'Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Linear Regression Regularized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "lrr = Lasso(alpha=0.01).fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_lrr_train = lrr.predict(x_train)\n",
    "yhat_lrr = lrr.predict(x_val)\n",
    "\n",
    "# performance\n",
    "lrr_result_train = ml_error('Linear Regression Regularized Train', yeojohnson_inverse(y_train), \n",
    "                           yeojohnson_inverse(yhat_lrr_train))\n",
    "lrr_result_val = ml_error('Linear Regression Regularized Val', y_val, \n",
    "                         yeojohnson_inverse(yhat_lrr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Linear Regression Model  - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr = Lasso(alpha=0.01)\n",
    "lrr_result_cv = cross_validation(exploratory_data_analysis, lrr, 'Linear Regression Regularized')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "rf = ensemble.RandomForestRegressor(n_jobs=-1, random_state=42).fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_rf_train = rf.predict(x_train)\n",
    "yhat_rf = rf.predict(x_val)\n",
    "\n",
    "# performance\n",
    "rf_result_train = ml_error('Random Forest Regressor Train', yeojohnson_inverse(y_train), yeojohnson_inverse(yhat_rf_train))\n",
    "rf_result_val = ml_error('Random Forest Regressor Val', y_val, yeojohnson_inverse(yhat_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Random Forest Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "rf_result_cv = cross_validation(exploratory_data_analysis, rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBRegressor(n_jobs=-1, random_state=42).fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_xgb_train = model_xgb.predict(x_train)\n",
    "yhat_xgb_val = model_xgb.predict(x_val)\n",
    "\n",
    "# performance\n",
    "xgb_result_train = ml_error('XGBoost Regressor Train', yeojohnson_inverse(y_train), yeojohnson_inverse(yhat_xgb_train))\n",
    "xgb_result_val = ml_error('XGBoost Regressor Val', y_val, yeojohnson_inverse(yhat_xgb_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 XGBoost Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(n_jobs=-1, random_state=42)\n",
    "xgb_result_cv = cross_validation(exploratory_data_analysis, model_xgb, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Compare Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>11.322</td>\n",
       "      <td>16.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Train</td>\n",
       "      <td>10.691</td>\n",
       "      <td>16.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Val</td>\n",
       "      <td>10.672</td>\n",
       "      <td>16.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Regularized Train</td>\n",
       "      <td>10.692</td>\n",
       "      <td>16.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Regularized Val</td>\n",
       "      <td>10.673</td>\n",
       "      <td>16.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor Train</td>\n",
       "      <td>4.235</td>\n",
       "      <td>7.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Regressor Val</td>\n",
       "      <td>10.830</td>\n",
       "      <td>16.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor Train</td>\n",
       "      <td>3.583</td>\n",
       "      <td>6.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor Val</td>\n",
       "      <td>12.005</td>\n",
       "      <td>17.879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "                            Model Name    MAE   RMSE\n",
       "\u001b[1;36m0\u001b[0m                        Average Model \u001b[1;36m11.322\u001b[0m \u001b[1;36m16.580\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m              Linear Regression Train \u001b[1;36m10.691\u001b[0m \u001b[1;36m16.400\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m                Linear Regression Val \u001b[1;36m10.672\u001b[0m \u001b[1;36m16.985\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m  Linear Regression Regularized Train \u001b[1;36m10.692\u001b[0m \u001b[1;36m16.400\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m    Linear Regression Regularized Val \u001b[1;36m10.673\u001b[0m \u001b[1;36m16.986\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m        Random Forest Regressor Train  \u001b[1;36m4.235\u001b[0m  \u001b[1;36m7.689\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m          Random Forest Regressor Val \u001b[1;36m10.830\u001b[0m \u001b[1;36m16.277\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m              XGBoost Regressor Train  \u001b[1;36m3.583\u001b[0m  \u001b[1;36m6.412\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m                XGBoost Regressor Val \u001b[1;36m12.005\u001b[0m \u001b[1;36m17.879\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([baseline_result, lr_result_train, lr_result_val, lrr_result_train, \n",
    "                    lrr_result_val, rf_result_train, rf_result_val, \n",
    "                    xgb_result_train, xgb_result_val])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, our models are similar, with an emphasis on linear regression and random forest, but we will not be making any decisions at single performance metrics as they may contain randomization bias, we will evaluate through a technique that addresses this, cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Real Performance - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>MAE CV</th>\n",
       "      <th>RMSE CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Train</td>\n",
       "      <td>10.33 +/- 0.33</td>\n",
       "      <td>15.91 +/- 0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression Val</td>\n",
       "      <td>10.97 +/- 0.4</td>\n",
       "      <td>16.57 +/- 1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression Regularized Train</td>\n",
       "      <td>10.33 +/- 0.33</td>\n",
       "      <td>15.92 +/- 0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression Regularized Val</td>\n",
       "      <td>10.97 +/- 0.36</td>\n",
       "      <td>16.51 +/- 1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Train</td>\n",
       "      <td>4.05 +/- 0.14</td>\n",
       "      <td>7.4 +/- 0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Val</td>\n",
       "      <td>12.54 +/- 0.57</td>\n",
       "      <td>17.19 +/- 0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Train</td>\n",
       "      <td>2.95 +/- 0.11</td>\n",
       "      <td>5.41 +/- 0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Val</td>\n",
       "      <td>12.98 +/- 0.75</td>\n",
       "      <td>18.25 +/- 0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "                            Model name          MAE CV         RMSE CV\n",
       "\u001b[1;36m0\u001b[0m              Linear Regression Train  \u001b[1;36m10.33\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.33\u001b[0m  \u001b[1;36m15.91\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.41\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m                Linear Regression Val   \u001b[1;36m10.97\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.4\u001b[0m  \u001b[1;36m16.57\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m1.39\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m  Linear Regression Regularized Train  \u001b[1;36m10.33\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.33\u001b[0m  \u001b[1;36m15.92\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.41\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    Linear Regression Regularized Val  \u001b[1;36m10.97\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.36\u001b[0m  \u001b[1;36m16.51\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m1.31\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m                  Random Forest Train   \u001b[1;36m4.05\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.14\u001b[0m    \u001b[1;36m7.4\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.26\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m                    Random Forest Val  \u001b[1;36m12.54\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.57\u001b[0m  \u001b[1;36m17.19\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.48\u001b[0m\n",
       "\u001b[1;36m0\u001b[0m                        XGBoost Train   \u001b[1;36m2.95\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.11\u001b[0m   \u001b[1;36m5.41\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.15\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m                          XGBoost Val  \u001b[1;36m12.98\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.75\u001b[0m  \u001b[1;36m18.25\u001b[0m +\u001b[35m/\u001b[0m\u001b[95m-\u001b[0m \u001b[1;36m0.85\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cv = pd.concat([lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv])\n",
    "result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can draw the following conclusions:\n",
    "1) We managed to beat our baseline, which is a weighted average\n",
    "2) The best models are linear, which demonstrates the linearity of the data.\n",
    "3) There is a technical tie and so we will choose linear regression to preserve the idea of simplicity. This also means that the model doesn't need Fine Tunning, so we'll skip this step.\n",
    "\n",
    "For future cycles we can test other models that explore the data space in different ways and even use an ensemble of models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (video_games_analysis)",
   "language": "python",
   "name": "kedro_video_games_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
